VZLUSAT has a much more noisy behaviour, and that is not something that reflect the actual link state, but is something that is related to how the signal power is calculated.

![alt text](screenshots/image-77.png)
My goal is that it should the yellow lines for the whole thing

There are some outliers
![alt text](screenshots/image-76.png)

Interference
![alt text](screenshots/image-78.png)
![alt text](screenshots/image-79.png)


More like that the noise power is affected by the clean signal power
![alt text](screenshots/image-80.png)


![alt text](screenshots/image-81.png)


There are some weird things
![alt text](screenshots/image-82.png)



I dont know why this one looks like shit

Finer resolution
![alt text](screenshots/image-83.png)

Still very very noisy data. I am guessing the only smart solution is making a moving average on the data. Then it will be called the truth that a model will have to predict. It is not completely stupid, but not that sexy.


Checking how the outliers look in the waterfall plot
![alt text](screenshots/image-84.png)
![alt text](screenshots/image-85.png)
Only two that are very fucked, and should be discarded


I do not like the noise:

Rectangular window
![alt text](screenshots/image-87.png)

Hamming windowed moving average
![alt text](screenshots/image-86.png)
larger window
![alt text](screenshots/image-88.png)

time resolution of 0.01 and fft size 256
![alt text](screenshots/image-89.png)

Better moving average with padding
![alt text](screenshots/image-113.png)
However still many points that we dont like

The red line looks more like a real signal. I am going to make it crazier. it was not that different unfortunately

I reduced the resolution to 128 and time to 0.01
![alt text](screenshots/image-90.png)

I can now see the noise. And the inteference. How large can the doppler shift be? it is never larger than 50k

FD=(v/c)*f
v=7600km/s max
c=3*10^8 m/s
f=437MHz

Max doppler= 11kHz
sampling rate is 250kHz
fft resolution is obj_act[].noise_obj.fft_size

If max value of the fft in valid range is not 10 times larger than the obj_act.noise, the data is an outlier and should be removed.


The variance cannot directly be used for anything unfortunately. unless maybe no, even normalising is not doing anything....

the noise could probably also be found by a histogram instead of just the average of specific bins

![alt text](screenshots/image-91.png)
larger
![alt text](screenshots/image-92.png)

not that much was gained from going to 0.005, but 0.01 and 32 are my recommended values

LPC of order 1000 (basically AR(1000)) where weights were found from 1 pass
![alt text](screenshots/image-93.png)
Not too bad for such a simple model
![alt text](screenshots/image-94.png)




When doing Machine Learning, each point should basically work by itself. This means each point should have the information about the previous points if that information is usefull

I tried to make chatten provide new ideas for features that could be calculated for each value
Statistical Features
Statistical measures can capture variations, trends, and spread in the data.

# Rolling Statistics (e.g., Last 5 Seconds)

Mean (already implemented)
Standard deviation
Variance
Median
Range (max - min)
Interquartile range (IQR)
Global Trends

Cumulative sum
Cumulative mean
Skewness and Kurtosis

Skewness: Measures data symmetry.
Kurtosis: Measures whether data tails are heavy or light compared to a normal distribution.
Change Metrics

Rate of change: Difference between consecutive values.
Percentage change: Relative rate of change compared to the previous value.
# Frequency-Domain Features
Signal features in the frequency domain often highlight periodicity or noise.

Power Spectral Density (PSD)

Quantifies the energy present at various frequency components.
Useful for identifying dominant frequencies in the signal.
Dominant Frequency

The frequency component with the highest amplitude in the Fourier Transform.
Harmonics

The presence and strength of harmonics in the frequency spectrum.
Signal Energy

Calculated as the sum of squared values over a window.
# Time-Series Decomposition Features
Decompose your signal into components for feature extraction.

Trend

The underlying long-term progression in the data (e.g., smoothed using moving averages or polynomial fitting).
Seasonality

Extract periodic patterns (daily, weekly, etc.) using methods like STL decomposition.
Residual

The remaining part of the signal after removing trend and seasonality.
Outlier and Event Detection
Outlier Count

Number of outliers in the last 5 seconds (e.g., using thresholds or Z-scores).
Amplitude Threshold

Count of values exceeding a certain threshold (high or low).
Event Durations

Duration of spikes, dips, or flat regions in the signal.
# Signal Quality Features
Features that measure the reliability or noise level of the signal.

Signal-to-Noise Ratio (SNR)

Ratio of signal power to noise power.
Noise Variance

Variance of the noise component.
Entropy

Shannon entropy: Measures the uncertainty or randomness in the signal.
Signal Smoothness

Metrics like Mean Absolute Difference (MAD) between consecutive samples.
# Correlation Features
If multiple signals are available, cross-correlation can capture relationships.

Cross-Correlation

Correlation between clean_sig_abs and other signals (e.g., pointing error, noise).
Lagged Correlation

Correlation between a signal and itself at different time lags.
# Event-Based Features
Peak Detection

Count of peaks or troughs in the last 5 seconds.
Amplitude of the highest peak.
Peak-to-Peak Interval

Time between consecutive peaks.
Peak Symmetry

Ratio of positive to negative peaks.
Time and Context Features
Time of Day

Include the timestamp as a feature (e.g., hour of the day or day of the week) if patterns vary by time.
Station Characteristics

Include contextual information such as station_obj.dist, azimuth, or elevation to help the model.
# Advanced Features
Autoregressive Coefficients

Fit an AR or ARIMA model to the signal and use the coefficients as features.
Wavelet Transform Coefficients

Perform wavelet decomposition to capture both time and frequency characteristics.
Dynamic Time Warping (DTW) Distance

Compare the current signal window to a template or reference signal.
Lyapunov Exponent

Measures the chaos in the signal.
Fractal Dimension

Quantifies complexity or self-similarity in the signal.


But if i want to predict 10 seconds into the future, all the values except time, set_azimuth, set_elevation, distance are unknown (as these are deterministic and the others are measured) for the data point. The mean of the last 5 seconds must then be the mean of the 15 to 10 seconds old samples.

In practice it also do not make sense to calculate the signal quality 10 seconds into the future 100 times a second. However it is also nice to have a reasonable amount of data for regression for example. It could be just be a longer time span and then weigh the samples so the newest samples are the most important.

What about the time aspect?
Basically the slope for the regression part can have the slope be in time. Maybe the slope is calculated from 5 or 1000 points, Maybe this value could also be appended? In that way it can find out how much weight should be used for the prediction.
what about the start points?

Tried adding features to each point so it is not dependant on the previous indicies values
![alt text](screenshots/image-97.png)
![alt text](screenshots/image-96.png)

What we can see is that if the points are low or the MSE is high, the prediction will be shit, and we therefore cannot trust it. This could be added for a second degree polynomial. If it does not fit the data, dont use it in the model, easy as that. We are going to get so many features


New results rolling in
![alt text](screenshots/image-100.png)
with the following weights
![alt text](screenshots/image-99.png)

So the mean of the old data is apparently important. The polynomial fitting was not important.
These were the settings
gbr = GradientBoostingRegressor(loss='squared_error',
                                learning_rate=0.1,
                                n_estimators=300,
                                max_depth=5, 
                                random_state=23)

Sidder og struggler med at have 0 ere som ikke findes i dataen
![alt text](screenshots/image-101.png)
Prøvede at finde fejlen i koden, men selv i variable terminalen kan jeg ikke se noget som helst. WTF

Jeg skal også lige finde ud af hvordan min prediction skal være hvis jeg står et sted hvor jeg ikke har nogle tal. Der er lav chance da det er 20 sekunder, men det sker efter 20 sekunder ved vi nok ikke en fucking skid.


Have a feeling that when using standard scaler instead of min max, features with a large dynamic range, noise power for example, get much larger



Using doppler shift to find the interesting bins.
![alt text](screenshots/image-102.png) should make it clearer which ones have signal and which have not

![alt text](screenshots/image-103.png)

KEIN
Overhovedet ikke perfekt, men lovende
![alt text](screenshots/image-104.png)


def _power(self, data: np.ndarray):
        """Calculates frequency components of absolute power based on the I/Q
        samples in `data` and the frequency resolution of `fft_size`       
        """
        offset = data.size % self._fft_size
        entries = data[:-offset].reshape((-1, self._fft_size))
        fft = np.fft.fft(entries, axis=1) * 1/self._fft_size
        fft = np.fft.fftshift(fft)
        
        signal_bandwidth =15e3 #evaluated from fft
        max_doppler= 11e3*2
        valid_range_bins = int(np.round(((signal_bandwidth + max_doppler) / 2) / (250e3 / self._fft_size)))
        center_bin = self._fft_size // 2  # Ensure this is an integer
        signal = np.mean(fft[:, center_bin - valid_range_bins : center_bin + valid_range_bins])
        noise = np.mean(np.concatenate([fft[:, :center_bin - valid_range_bins], 
                                 fft[:, center_bin + valid_range_bins + 1:]], axis=1))


        # Check if the signal power is at least twice the noise power
        if signal > 2 * noise:
            fft = fft[np.where(signal > 2 * noise)[0]]
            power = fft.real**2 + fft.imag**2
            power_abs = np.mean(power / 100, axis=0)
            power_ant = power_abs / 10**(60/10)
        else:
            power_ant = np.ones(self._fft_size) * 1e-14  # Noise floor

        return power_ant



What i try is the following:
![alt text](screenshots/image-105.png)
![alt text](screenshots/image-106.png)

In the second one the signal is not dripping. I dont want the drip

However waterfall looks like piss, and we can see that there are nowhere 



Using a window to find out when the transmitter is transmitting or not
![alt text](screenshots/image-107.png)
![alt text](screenshots/image-108.png)

Holy fuck
Trying to change parameters:
changing to 3*noise power - no improvement
![alt text](screenshots/image-109.png)

Changing to smaller window size /20 instead of /10 - bit less drip
![alt text](screenshots/image-110.png)

Hamming window with window size 1/10

![alt text](screenshots/image-111.png)

Hamming window with window size 1/50
![alt text](screenshots/image-112.png)


Thinking about implementing some outlier detection, as the data has less noise now
![alt text](screenshots/image-114.png)


Information about the satellite
https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11530/2575862/Development-of-CubeSat-with-COTS-camera-enabling-EO-with-high/10.1117/12.2575862.full?SSO=1

"Tx power is 750 mW and modulation used is MSK up to 9600 bps. Antenna type is turnstile quad monopole which provides good omnidirectional characteristic without fade outs. There is CCSDS protocol with CubeSat Space Protocol at network layer. There is also function of radio beacon transmitting at the same frequency. Power consumption of communication subsystem is 250 mW when receiving and 1800 mW when transmitting. UHF uses omnidirectional antenna."

satnogs database
https://network.satnogs.org/observations/?norad=51085

data about the satellite, very interesting, i want to download, but dont know how
https://dashboard.satnogs.org/d/L8ywE9oMz/vzlusat-2?orgId=1&from=1729144033747&to=1729213191028

Mostly 4800 MSK
 ![alt text](screenshots/image-115.png)

SÅ HVORFOR FUCK ER DER 5-7 tapper? er det fordi det er en eller anden kendt pilot sekvens?





Ny data - ser generelt rigtigt godt ud
![alt text](screenshots/image-116.png)

Dog er der stadig et problem ved nogle få, mindst 1. Måske kan jeg vurdere det ud fra afstanden fra moving mean? Så kan jeg fjerne de enkelte punkter eller hele passes
![alt text](screenshots/image-117.png)


Trying to remove outlier from distance from the moving mean, which is a bit illegal, but also very effective
![alt text](screenshots/image-118.png)
![alt text](screenshots/image-120.png)
Maybe do several times?

Three iterations, still not good....
![alt text](screenshots/image-121.png)

I am thinking that it can be done once and then it is okay that a lot of points die. maybe squared error of 5 which is close to the noise part being as low as 2.something from the mean.

If the model ends up having 3 db higher predictions than the other model in average, RMSE, it will equal a 3.3 times 3dB improvement as log2(1+something) = log10(1+something)*3.3??? NOPE, it depends on the level, so it has to be evaluated per timestep

This i think makes sense to be a benchmark
![alt text](screenshots/image-122.png)
Just a zero order hold and a buffer. Or maybe FSPL and a buffer. Later in the presentation ML, NN and AR was shown on the same plot. I think that this is how things should be.


If trained to have 99% of predictions under, it will have a different weight distribution than if trained for LMS. It is easier to compare if all models are trained equally
![alt text](screenshots/image-123.png)
![alt text](screenshots/image-124.png)

Normalt er det 
![alt text](screenshots/image-125.png)
![alt text](screenshots/image-126.png)

We make the loss function to MSE so it will average to an error of 0.
![alt text](screenshots/image-127.png)
![alt text](screenshots/image-128.png)



145 training sets
35 validation sets

30 seconds load and disregard outliers
5 minutes produce datasets
3 minutes gradient boosting
0.1 seconds LGBM
10 seconds Random forrest

15 minutes for a very simple ARIMA calculation, so i gave up and changed to LPC, which is just AR
For LPC it takes 0.8 seconds due to matrix calculation instead of for loops

If tweaking the value by 10%, we achieved something that shows a rather promising reason that we have to allign the fuckers.
![alt text](screenshots/image-129.png)

It could be MAE, as it is easy.

Another interesting thing could be to compare the errors in regards to time. It is easy to do. How does it handle the first 30 seconds compared to the middle ones?

I did differencing on LPC or AR(20) and d=1, and it just works
![alt text](screenshots/image-130.png)

Mean error adjustment
![alt text](screenshots/image-134.png)

Median error adjustment
![alt text](screenshots/image-133.png)
![alt text](screenshots/image-132.png)